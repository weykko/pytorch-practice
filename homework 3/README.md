# Домашнее задание к уроку 3: Полносвязные сети

## Задание 1: Эксперименты с глубиной сети

### 1.1 Сравнение моделей разной глубины

Результаты обучения моделей с различным количеством слоев:

```
1_layer:
Итоговая точность train: 0.9274
Итоговая точность test: 0.9214
2_layers:
Итоговая точность train: 0.9940
Итоговая точность test: 0.9778
3_layers:
Итоговая точность train: 0.9929
Итоговая точность test: 0.9801
5_layers:
Итоговая точность train: 0.9907
Итоговая точность test: 0.9788
7_layers:
Итоговая точность train: 0.9895
Итоговая точность test: 0.9780
```

Кривые обучения 3-слойной модели:

![3_layers.png](plots%2F3_layers.png)

При увеличении количества слоев время обучения возрастает.  
Все результаты находятся в [depth_experiments.txt](results%2Fdepth_experiments.txt)

### 1.2 Анализ переобучения

Как видно все модели имеет большую точность на тренировочном наборе, это сигнализирует о переобучении моделей.  
3-слойная модель показала лучшую точность на тестовом наборе. Начиная с 2 слоёв, точность улучшается слабо, несмотря на резкий рост числа параметров.

Результаты обучения моделей с регуляризацией:

```
2_layers_reg:
Итоговая точность train: 0.9880
Итоговая точность test: 0.9789
3_layers_reg:
Итоговая точность train: 0.9867
Итоговая точность test: 0.9820
5_layers_reg:
Итоговая точность train: 0.9810
Итоговая точность test: 0.9830
7_layers_reg:
Итоговая точность train: 0.9776
Итоговая точность test: 0.9819
```

Кривые обучения 5-слойной модели с регуляризацией:

![5_layers_reg.png](plots%2F5_layers_reg.png)

Использование Dropout и BatchNorm уменьшает или полностью убирает переобучение моделей.