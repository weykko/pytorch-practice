
# Описание решения

## 1.1 Расширение линейной регрессии

### Внесенные изменения

1. **Регуляризация**  
   Мы добавили поддержку L1 и L2 регуляризаций в модель линейной регрессии, что помогает предотвратить переобучение и улучшить обобщающую способность модели.

2. **Early Stopping**  
   Мы реализовали механизм ранней остановки, который останавливает обучение, если значение ошибки на валидации не улучшается в течение определенного числа эпох. 

### Результаты
После добавления регуляризаций модель показала улучшенную способность обобщать на новые данные, снижая переобучение при большом количестве эпох.
Механизм ранней остановки эффективно сокращает время обучения и предотвращает излишнюю подгонку модели.

---

## 1.2 Расширение логистической регрессии

### Внесенные изменения

1. **Поддержка многоклассовой классификации**
2. **Метрики качества**
   - Precision (Точность)
   - Recall
   - F1-score
   - ROC-AUC

3. **Визуализация confusion matrix**  
   Матрица ошибок (confusion matrix) была построена с помощью **matplotlib**

![confusion_matrix.png](plots%2Fconfusion_matrix.png)
### Результаты
Модель теперь поддерживает многоклассовую классификацию и выводит важные метрики, которые дают полное представление о производительности модели.
Визуализация матрицы ошибок позволила наглядно понять, какие классы модель путает чаще всего.

---

## 2.1 Кастомный Dataset класс

### Реализация

Был создан собственный класс CSVDataset, унаследованный от **`torch.utils.data.Dataset`**.

### Результаты
Наш класс **CSVDataset** позволяет легко работать с данными из CSV-файлов, поддерживает различные типы задач и обеспечивает автоматическое преобразование признаков.

---

## 2.2 Эксперименты с датасетами

### Регрессия

Использовался датасет **`regression_dataset.csv`**

```
MSE (regression): 161.42593383789062
```

### Классификация

Использовался датасет **`classification_dataset.csv`**
```
Accuracy (classification): 0.76
Precision: 0.7352941176470589
Recall:    0.8928571428571429
F1-score:  0.8064516129032258
ROC-AUC:   0.8133116883116882
```
   ![confusion_matrix2.png](plots%2Fconfusion_matrix2.png)

---

## 3.1 Исследование гиперпараметров

### Эксперименты
Мы провели эксперименты с различными комбинациями гиперпараметров:
- Скорости обучения: 0.001, 0.01, 0.1
- Размеры батчей: 16, 32
- Оптимизаторы: SGD, Adam, RMSprop

Для каждой комбинации гиперпараметров вычислялся **MSE** на валидационных данных.

![hyperparameter_experiments.png](plots%2Fhyperparameter_experiments.png)
## 3.2 Feature Engineering

Генерируются полиномиальные признаки (2-й степени) из признаков
Применяется нормализация
Обучается простая линейная модель
Сравнивается результат по метрике MSE

```
Feature Engineering
MSE for Base Model: 1219.787109375
MSE with Poly Features: 0.0229469183832407
```